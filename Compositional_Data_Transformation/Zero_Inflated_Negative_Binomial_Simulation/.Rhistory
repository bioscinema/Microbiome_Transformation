mu_b <- exp(eta_significant * x_b + beta) / (1 + exp(eta_significant * x_b + beta))
# Simulate data for group A
group_a <- rbeta(n1, mu_a * nu_a, (1 - mu_a) * nu_a)
# Simulate data for group B
group_b <- rbeta(n2, mu_b * nu_b, (1 - mu_b) * nu_b)
# Combine and apply zero-inflation
combined <- c(group_a, group_b)
combined <- combined * (rbinom(n, 1, 1 - q) == 1)
# Bind the values to the main data frame
data <- cbind(data, setNames(data.frame(combined), paste0('X', j)))
}
# Generate values for non-significant variables
for (j in (p/2+1):p) {
# Calculate mu for group A and B
mu_a <- exp(eta_not_significant * x_a + beta) / (1 + exp(eta_not_significant * x_a + beta))
mu_b <- exp(eta_not_significant * x_b + beta) / (1 + exp(eta_not_significant * x_b + beta))
# Simulate data for group A
group_a <- rbeta(n1, mu_a * nu_a, (1 - mu_a) * nu_a)
# Simulate data for group B
group_b <- rbeta(n2, mu_b * nu_b, (1 - mu_b) * nu_b)
# Combine and apply zero-inflation
combined <- c(group_a, group_b)
combined <- combined * (rbinom(n, 1, 1 - q) == 1)
# Bind the values to the main data frame
data <- cbind(data, setNames(data.frame(combined), paste0('X', j)))
}
return(data)
}
n <- 100
p <- 50
eta_significant <- -0.7
eta_not_significant = 0
nu_a <- 5
nu_b <- 5
x_a <- 1
x_b <- 2
beta = -2
q = 0.7
generated_data = generate_zero_inflated_beta_data(n, p, eta_significant, eta_not_significant, nu_a, nu_b, x_a, x_b, beta, q)
data = generated_data[,c(1,2)]
colnames(data) = c("group", "value")
data_without_zero = replace_zeros_all(data)
boxcox_transformation(data_without_zero)
dataframe = data
x <- dataframe$value
boxcox_result <- boxcox(lm(x ~ 1), plotit = FALSE)
library(MASS)
boxcox_transformation <- function(dataframe) {
x <- dataframe$value
boxcox_result <- boxcox(lm(x ~ 1), plotit = FALSE)
lambda_optimal <- boxcox_result$x[which.max(boxcox_result$y)]
# Apply the optimal lambda
if (lambda_optimal == 0) {
transformed_data <- log(x)
} else {
transformed_data <- (x^lambda_optimal - 1) / lambda_optimal
}
return(data.frame(group = dataframe$group, value = transformed_data))
}
replace_zeros_all <- function(data) {
numeric_cols <- sapply(data, is.numeric)  # Identify numeric columns
data[numeric_cols] <- lapply(data[numeric_cols], function(x) {
x[x == 0] <- 10^-3
return(x)
})
return(data)
}
generate_zero_inflated_beta_data <- function(n, p, eta_significant, eta_not_significant, nu_a, nu_b, x_a, x_b, beta, q) {
# Calculate the number of observations per group
n1 <- n / 2
n2 <- n / 2
# Create a grouping variable
group <- factor(rep(c('A', 'B'), each = n1))
# Initialize an empty data frame to store the results
data <- data.frame(group = group)
# Generate values for significant variables
for (j in 1:(p/2)) {
# Calculate mu for group A and B
mu_a <- exp(eta_significant * x_a + beta) / (1 + exp(eta_significant * x_a + beta))
mu_b <- exp(eta_significant * x_b + beta) / (1 + exp(eta_significant * x_b + beta))
# Simulate data for group A
group_a <- rbeta(n1, mu_a * nu_a, (1 - mu_a) * nu_a)
# Simulate data for group B
group_b <- rbeta(n2, mu_b * nu_b, (1 - mu_b) * nu_b)
# Combine and apply zero-inflation
combined <- c(group_a, group_b)
combined <- combined * (rbinom(n, 1, 1 - q) == 1)
# Bind the values to the main data frame
data <- cbind(data, setNames(data.frame(combined), paste0('X', j)))
}
# Generate values for non-significant variables
for (j in (p/2+1):p) {
# Calculate mu for group A and B
mu_a <- exp(eta_not_significant * x_a + beta) / (1 + exp(eta_not_significant * x_a + beta))
mu_b <- exp(eta_not_significant * x_b + beta) / (1 + exp(eta_not_significant * x_b + beta))
# Simulate data for group A
group_a <- rbeta(n1, mu_a * nu_a, (1 - mu_a) * nu_a)
# Simulate data for group B
group_b <- rbeta(n2, mu_b * nu_b, (1 - mu_b) * nu_b)
# Combine and apply zero-inflation
combined <- c(group_a, group_b)
combined <- combined * (rbinom(n, 1, 1 - q) == 1)
# Bind the values to the main data frame
data <- cbind(data, setNames(data.frame(combined), paste0('X', j)))
}
return(data)
}
n <- 100
p <- 50
eta_significant <- -0.7
eta_not_significant = 0
nu_a <- 5
nu_b <- 5
x_a <- 1
x_b <- 2
beta = -2
q = 0.7
generated_data = generate_zero_inflated_beta_data(n, p, eta_significant, eta_not_significant, nu_a, nu_b, x_a, x_b, beta, q)
data = generated_data[,c(1,2)]
colnames(data) = c("group", "value")
data_without_zero = replace_zeros_all(data)
boxcox_transformation(data_without_zero)
data_without_zero$value
data_without_zero$value > 0
library(MASS)
# Function to apply Box-Cox transformation to all numeric columns
boxcox_transformation <- function(data) {
numeric_cols <- sapply(data, is.numeric)  # Identify numeric columns
transformed_data <- data  # Create a copy to store transformed data
for (col in names(data)[numeric_cols]) {
x <- data[[col]]
boxcox_result <- boxcox(lm(x ~ 1), plotit = FALSE)
lambda_optimal <- boxcox_result$x[which.max(boxcox_result$y)]
# Apply the optimal lambda
if (lambda_optimal == 0) {
transformed_data[[col]] <- log(x)
} else {
transformed_data[[col]] <- (x^lambda_optimal - 1) / lambda_optimal
}
}
return(transformed_data)
}
# Function to generate zero-inflated beta data
generate_zero_inflated_beta_data <- function(n, p, eta_significant, eta_not_significant, nu_a, nu_b, x_a, x_b, beta, q) {
# Calculate the number of observations per group
n1 <- n / 2
n2 <- n / 2
# Create a grouping variable
group <- factor(rep(c('A', 'B'), each = n1))
# Initialize an empty data frame to store the results
data <- data.frame(group = group)
# Generate values for significant variables
for (j in 1:(p/2)) {
# Calculate mu for group A and B
mu_a <- exp(eta_significant * x_a + beta) / (1 + exp(eta_significant * x_a + beta))
mu_b <- exp(eta_significant * x_b + beta) / (1 + exp(eta_significant * x_b + beta))
# Simulate data for group A
group_a <- rbeta(n1, mu_a * nu_a, (1 - mu_a) * nu_a)
# Simulate data for group B
group_b <- rbeta(n2, mu_b * nu_b, (1 - mu_b) * nu_b)
# Combine and apply zero-inflation
combined <- c(group_a, group_b)
combined <- combined * (rbinom(n, 1, 1 - q) == 1)
# Bind the values to the main data frame
data <- cbind(data, setNames(data.frame(combined), paste0('X', j)))
}
# Generate values for non-significant variables
for (j in (p/2+1):p) {
# Calculate mu for group A and B
mu_a <- exp(eta_not_significant * x_a + beta) / (1 + exp(eta_not_significant * x_a + beta))
mu_b <- exp(eta_not_significant * x_b + beta) / (1 + exp(eta_not_significant * x_b + beta))
# Simulate data for group A
group_a <- rbeta(n1, mu_a * nu_a, (1 - mu_a) * nu_a)
# Simulate data for group B
group_b <- rbeta(n2, mu_b * nu_b, (1 - mu_b) * nu_b)
# Combine and apply zero-inflation
combined <- c(group_a, group_b)
combined <- combined * (rbinom(n, 1, 1 - q) == 1)
# Bind the values to the main data frame
data <- cbind(data, setNames(data.frame(combined), paste0('X', j)))
}
return(data)
}
# Generate data
n <- 100
p <- 50
eta_significant <- -0.7
eta_not_significant <- 0
nu_a <- 5
nu_b <- 5
x_a <- 1
x_b <- 2
beta <- -2
q <- 0.7
generated_data <- generate_zero_inflated_beta_data(n, p, eta_significant, eta_not_significant, nu_a, nu_b, x_a, x_b, beta, q)
# Ensure data without zeros (for demonstration)
data_without_zero <- generated_data
data_without_zero[data_without_zero == 0] <- 10^-5
# Apply Box-Cox transformation to the processed data
boxcox_transformed <- boxcox_transformation(data_without_zero)
data = read.csv("all_summarized_results_GUniFrac.csv")
setwd("~/Desktop/Microbiome_Transformation 9.26.15â€¯AM/Compositional_Data_Transformation/GUniFrac")
data = read.csv("all_summarized_results_GUniFrac.csv")
head(data)
library(tidyverse)
models <- list()
# Loop through each transformation and fit the linear model
transformations <- unique(data$transformation)
for (trans in transformations) {
subset_data <- data %>%
filter(transformation == trans)
model <- lm(mean_power ~ diff_otu_direct + diff_otu_mode + depth_mu + depth_theta + covariate_eff_sd+ confounder_eff_sd+ depth_conf_factor, data = subset_data)
models[[trans]] <- model
}
output_file <- "model_summaries.txt"
# Redirect output to the file
sink(output_file)
# Print the summary of each model
for (transformation in names(models)) {
cat("\nTransformation:", transformation, "\n")
print(summary(models[[transformation]]))
}
sink()
cat("Model summaries have been saved to", output_file, "\n")
# Load necessary libraries
library(tidyverse)
library(knitr)
library(kableExtra)
install.packages("kableExtra")
# Load necessary libraries
library(tidyverse)
library(knitr)
library(kableExtra)
# Read the data
data <- read.csv("all_summarized_results_GUniFrac.csv")
# Initialize list to store models
models <- list()
# Loop through each transformation and fit the linear model
transformations <- unique(data$transformation)
coefficients_list <- list()
for (trans in transformations) {
subset_data <- data %>%
filter(transformation == trans)
model <- lm(mean_power ~ diff_otu_direct + diff_otu_mode + depth_mu + depth_theta + covariate_eff_sd + confounder_eff_sd + depth_conf_factor, data = subset_data)
models[[trans]] <- model
# Extract coefficients and their p-values
coefs <- summary(model)$coefficients
coefs <- as.data.frame(coefs)
coefs$variable <- rownames(coefs)
coefs$transformation <- trans
coefficients_list[[trans]] <- coefs
}
# Combine all coefficients into one data frame
coefficients_df <- bind_rows(coefficients_list)
# Create a formatted table with significant variables in red
coefficients_df <- coefficients_df %>%
mutate(significance = ifelse(`Pr(>|t|)` < 0.05, "significant", "not significant"))
# Save the coefficients table to an HTML file with conditional formatting
output_file <- "coefficients_table.html"
kable(coefficients_df, format = "html", row.names = FALSE,
col.names = c("Estimate", "Std. Error", "t value", "Pr(>|t|)", "Variable", "Transformation", "Significance")) %>%
kable_styling() %>%
row_spec(which(coefficients_df$significance == "significant"), color = "red") %>%
save_kable(file = output_file)
cat("Coefficients table has been saved to", output_file, "\n")
# Save the model summaries to a text file
model_summaries_file <- "model_summaries.txt"
sink(model_summaries_file)
for (transformation in names(models)) {
cat("\nTransformation:", transformation, "\n")
print(summary(models[[transformation]]))
}
sink()
cat("Model summaries have been saved to", model_summaries_file, "\n")
# Load necessary libraries
library(tidyverse)
library(knitr)
library(kableExtra)
# Read the data
data <- read.csv("all_summarized_results_GUniFrac.csv")
# Initialize list to store models
models <- list()
# Loop through each transformation and fit the linear model
transformations <- unique(data$transformation)
coefficients_list <- list()
for (trans in transformations) {
subset_data <- data %>%
filter(transformation == trans)
model <- lm(mean_power ~ diff_otu_direct + diff_otu_mode + depth_mu + depth_theta + covariate_eff_sd + confounder_eff_sd + depth_conf_factor, data = subset_data)
models[[trans]] <- model
# Extract coefficients and their p-values
coefs <- summary(model)$coefficients
coefs <- as.data.frame(coefs)
coefs$variable <- rownames(coefs)
coefs$transformation <- trans
coefficients_list[[trans]] <- coefs
}
# Combine all coefficients into one data frame
coefficients_df <- bind_rows(coefficients_list) %>%
pivot_wider(names_from = variable, values_from = c("Estimate", "Pr(>|t|)")) %>%
rename_with(~ gsub("Estimate_", "", .)) %>%
rename_with(~ gsub("Pr\\(>\\|t\\|\\)_", "p_", .))
# Create a formatted table with significant variables in red
output_file <- "coefficients_table.html"
kable(coefficients_df, format = "html", row.names = FALSE) %>%
kable_styling() %>%
column_spec(which(grepl("^p_", colnames(coefficients_df))), color = ifelse(coefficients_df[, grepl("^p_", colnames(coefficients_df))] < 0.05, "red", "black")) %>%
save_kable(file = output_file)
# Load necessary libraries
library(tidyverse)
library(kableExtra)
# Read the data
data <- read.csv("all_summarized_results_GUniFrac.csv")
# Initialize list to store models
models <- list()
coefficients_list <- list()
# Loop through each transformation and fit the linear model
transformations <- unique(data$transformation)
for (trans in transformations) {
subset_data <- data %>%
filter(transformation == trans)
model <- lm(mean_power ~ diff_otu_direct + diff_otu_mode + depth_mu + depth_theta + covariate_eff_sd + confounder_eff_sd + depth_conf_factor, data = subset_data)
models[[trans]] <- model
# Extract coefficients and their p-values
coefs <- summary(model)$coefficients
coefs <- as.data.frame(coefs)
coefs$variable <- rownames(coefs)
coefs <- coefs %>%
mutate(transformation = trans) %>%
select(transformation, variable, Estimate, `Std. Error`, `t value`, `Pr(>|t|)`)
coefficients_list[[trans]] <- coefs
}
# Combine all coefficients into one data frame
coefficients_df <- bind_rows(coefficients_list)
# Reshape the data frame to have one row per transformation and variable names as columns
coefficients_wide <- coefficients_df %>%
pivot_wider(names_from = variable, values_from = c(Estimate, `Std. Error`, `t value`, `Pr(>|t|)`))
# Create a formatted table with significant variables in red
coefficients_wide <- coefficients_wide %>%
mutate(across(contains("Pr(>|t|)"), ~ifelse(. < 0.05, "significant", "not significant"), .names = "sig_{col}"))
# Create an HTML table
output_file <- "coefficients_table.html"
kable(coefficients_wide, format = "html", row.names = FALSE) %>%
kable_styling(full_width = TRUE) %>%
column_spec(3:ncol(coefficients_wide),
background = spec_color(ifelse(grepl("significant", names(coefficients_wide)), "red", "white"), end = 1, direction = -1)) %>%
save_kable(file = output_file)
library(tidyverse)
# Read the data
data <- read.csv("all_summarized_results_GUniFrac.csv")
# Initialize list to store models
models <- list()
coefficients_list <- list()
# Loop through each transformation and fit the linear model
transformations <- unique(data$transformation)
for (trans in transformations) {
subset_data <- data %>%
filter(transformation == trans)
model <- lm(mean_power ~ diff_otu_direct + diff_otu_mode + depth_mu + depth_theta + covariate_eff_sd + confounder_eff_sd + depth_conf_factor, data = subset_data)
models[[trans]] <- model
# Extract coefficients
coefs <- summary(model)$coefficients
coefs <- as.data.frame(coefs)
coefs$variable <- rownames(coefs)
coefs <- coefs %>%
mutate(transformation = trans) %>%
select(transformation, variable, Estimate)
coefficients_list[[trans]] <- coefs
}
# Combine all coefficients into one data frame
coefficients_df <- bind_rows(coefficients_list)
# Reshape the data frame to have one row per transformation and variable names as columns
coefficients_wide <- coefficients_df %>%
pivot_wider(names_from = variable, values_from = Estimate)
# Save the table to a CSV file
output_file <- "coefficients_table.csv"
write.csv(coefficients_wide, file = output_file, row.names = FALSE)
cat("Coefficients table has been saved to", output_file, "\n")
library(tidyverse)
# Read the data
data <- read.csv("all_summarized_results_GUniFrac.csv")
# Initialize list to store models
models <- list()
coefficients_list <- list()
# Loop through each transformation and fit the linear model
transformations <- unique(data$transformation)
for (trans in transformations) {
subset_data <- data %>%
filter(transformation == trans)
model <- lm(mean_power ~ diff_otu_direct + diff_otu_mode + depth_mu + depth_theta + covariate_eff_sd + confounder_eff_sd + depth_conf_factor, data = subset_data)
models[[trans]] <- model
# Extract coefficients
coefs <- summary(model)$coefficients
coefs <- as.data.frame(coefs)
coefs$variable <- rownames(coefs)
coefs <- coefs %>%
mutate(transformation = trans) %>%
select(transformation, variable, Estimate)
coefficients_list[[trans]] <- coefs
}
# Combine all coefficients into one data frame
coefficients_df <- bind_rows(coefficients_list)
# Reshape the data frame to have one row per transformation and variable names as columns
coefficients_wide <- coefficients_df %>%
pivot_wider(names_from = variable, values_from = Estimate)
# Format all numeric values to 7 decimal places
coefficients_wide <- coefficients_wide %>%
mutate(across(where(is.numeric), ~sprintf("%.7f", .)))
# Save the table to a CSV file
output_file <- "coefficients_table.csv"
write.csv(coefficients_wide, file = output_file, row.names = FALSE)
cat("Coefficients table has been saved to", output_file, "\n")
library(tidyverse)
models <- list()
summary_non_significant_as_reference = read.csv("summary_non_significant_as_reference.csv")
setwd("/Users/yiqianzhang/Desktop/Microbiome_Transformation 9.26.15â€¯AM/Compositional_Data_Transformation/Zero_Inflated_Negative_Binomial_Simulation")
library(tidyverse)
models <- list()
summary_non_significant_as_reference = read.csv("summary_non_significant_as_reference.csv")
transformations <- unique(summary_non_significant_as_reference$transformation)
models <- list()
for (trans in transformations) {
subset_data <- summary_non_significant_as_reference %>%
filter(transformation == trans)
model <- lm(mean_power ~ alpha + beta0 + beta + q, data = subset_data)
models[[trans]] <- model
}
output_file <- "model_summaries_non_significant_as_reference.txt"
sink(output_file)
for (transformation in names(models)) {
cat("\nTransformation:", transformation, "\n")
print(summary(models[[transformation]]))
}
sink()
cat("Model summaries have been saved to", output_file, "\n")
model_summaries <- data.frame(Transformation = character(),
Intercept = numeric(),
alpha = numeric(),
beta0 = numeric(),
beta = numeric(),
q = numeric(),
stringsAsFactors = FALSE)
# Loop through each transformation and fit the linear regression model
for (trans in transformations) {
subset_data <- summary_non_significant_as_reference %>%
filter(transformation == trans)
model <- lm(mean_power ~ alpha + beta0 + beta + q, data = subset_data)
summary_model <- summary(model)
# Extract coefficients
intercept <- round(summary_model$coefficients[1, "Estimate"], 10)
alpha <- round(summary_model$coefficients[2, "Estimate"], 10)
beta0 <- round(summary_model$coefficients[3, "Estimate"], 10)
beta <- round(summary_model$coefficients[4, "Estimate"], 10)
q <- round(summary_model$coefficients[5, "Estimate"], 10)
# Add the model summary to the data frame
model_summaries <- rbind(model_summaries, data.frame(Transformation = trans,
Intercept = intercept,
alpha = alpha,
beta0 = beta0,
beta = beta,
q = q))
}
write.csv(model_summaries, "model_coefficient.csv", row.names = FALSE)
cat("Model summaries have been saved to model_coefficient.csv\n")
library(tidyverse)
models <- list()
summary_non_significant_as_reference = read.csv("summary_non_significant_as_reference.csv")
transformations <- unique(summary_non_significant_as_reference$transformation)
models <- list()
for (trans in transformations) {
subset_data <- summary_non_significant_as_reference %>%
filter(transformation == trans)
model <- lm(mean_power ~ alpha + beta0 + beta + q, data = subset_data)
models[[trans]] <- model
}
output_file <- "model_summaries_non_significant_as_reference.txt"
sink(output_file)
for (transformation in names(models)) {
cat("\nTransformation:", transformation, "\n")
print(summary(models[[transformation]]))
}
sink()
cat("Model summaries have been saved to", output_file, "\n")
model_summaries <- data.frame(Transformation = character(),
Intercept = numeric(),
alpha = numeric(),
beta0 = numeric(),
beta = numeric(),
q = numeric(),
stringsAsFactors = FALSE)
# Loop through each transformation and fit the linear regression model
for (trans in transformations) {
subset_data <- summary_non_significant_as_reference %>%
filter(transformation == trans)
model <- lm(mean_power ~ alpha + beta0 + beta + q, data = subset_data)
summary_model <- summary(model)
# Extract coefficients
intercept <- round(summary_model$coefficients[1, "Estimate"], 10)
alpha <- round(summary_model$coefficients[2, "Estimate"], 10)
beta0 <- round(summary_model$coefficients[3, "Estimate"], 10)
beta <- round(summary_model$coefficients[4, "Estimate"], 10)
q <- round(summary_model$coefficients[5, "Estimate"], 10)
# Add the model summary to the data frame
model_summaries <- rbind(model_summaries, data.frame(Transformation = trans,
Intercept = intercept,
alpha = alpha,
beta0 = beta0,
beta = beta,
q = q))
}
write.csv(model_summaries, "model_coefficient.csv", row.names = FALSE)
cat("Model summaries have been saved to model_coefficient.csv\n")
