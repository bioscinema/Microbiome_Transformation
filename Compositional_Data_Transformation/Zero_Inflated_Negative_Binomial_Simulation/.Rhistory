conf.otu.ind <- c(conf.otu.ind1,
sample(setdiff(1:(nOTU), diff.otu.ind), round(conf.nondiff.otu.pct * nOTU)))
## Calculate the new composition
eta.diff[setdiff(1:(nOTU), diff.otu.ind), ] <- 0
eta.conf[setdiff(1:(nOTU), conf.otu.ind), ] <- 0
eta.error <- matrix(rnorm(nOTU * nSam, 0, error.sd), nOTU, nSam)
eta.exp <- exp(t(eta.diff + eta.conf + eta.error))
eta.exp <- eta.exp * t(ref.otu.tab)
ref.otu.tab.prop <- eta.exp/rowSums(eta.exp)
ref.otu.tab.prop <- t(ref.otu.tab.prop)
## Simulate Sequencing Depth using Negative Binomial Distribution
nSeq <- rnegbin(nSam,
mu = depth.mu * exp(scale(X) * depth.conf.factor),
theta = depth.theta)
## Simulate Absolute Abundance of OTU
otu.tab.sim <- sapply(1:ncol(ref.otu.tab.prop),
function(i) rmultinom(1, nSeq[i], ref.otu.tab.prop[, i]))
colnames(otu.tab.sim) <- rownames(eta.exp)
rownames(otu.tab.sim) <- rownames(ref.otu.tab)
diff.otu.ind = (1:nOTU) %in% diff.otu.ind
conf.otu.ind = (1:nOTU) %in% conf.otu.ind
## Output
return(list(otu.tab.sim = otu.tab.sim, covariate = X, confounder = Z,
diff.otu.ind = diff.otu.ind, otu.names = idx.otu, conf.otu.ind = conf.otu.ind))
}
load("para1.RData")
names(para1)
Simulated_data = SimulateMSeqU(para = para1, nSam = 100, nOTU = 100, diff.otu.pct = 0.1,
diff.otu.direct = "unbalanced",
diff.otu.mode = "mix",
user_specified_otu = NULL,
covariate.type = "binary",
grp.ratio = 1, covariate.eff.mean = 1, covariate.eff.sd = 0,
confounder.type = "both",
conf.cov.cor = 0.6, conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0.1,
confounder.eff.mean = 0, confounder.eff.sd = 0, error.sd = 0,
depth.mu = 10000, depth.theta = 5, depth.conf.factor = 0, cont.conf = 0, epsilon = 0)
otu_df <- as.data.frame(Simulated_data$otu.tab.sim)
diff_otu_ids = Simulated_data$otu.names[Simulated_data$diff.otu.ind]
diff_otu_ids
meta.dat <- data.frame(X = Simulated_data$covariate, Z1 = Simulated_data$confounder[, 1],
Z2 = Simulated_data$confounder[, 2])
meta.dat$sample = rownames(meta.dat)
meta.dat
test_transformations <- function(simulated_data, transformation_functions) {
results_list <- list()
for (beta_s in names(simulated_data)) {
data <- simulated_data[[beta_s]]
results_list[[beta_s]] <- list()
for (trans_name in names(transformation_functions)) {
trans_func <- transformation_functions[[trans_name]]
transformed_data <- trans_func(data)
group1_data <- transformed_data[transformed_data$Group == "A", -1]
group2_data <- transformed_data[transformed_data$Group == "B", -1]
p_values <- numeric(ncol(group1_data))
for (i in 1:ncol(group1_data)) {
compare_data <- data.frame(
group = rep(c("A", "B"), each = nrow(group1_data)),
datas = c(group1_data[, i], group2_data[, i])
)
test_result <- t.test(datas ~ group, data = compare_data)
p_values[i] <- test_result$p.value
}
# Adjust the p-values using the Bonferroni method
adjusted_p_values <- p.adjust(p_values, method = "bonferroni")
results_list[[beta_s]][[trans_name]] <- adjusted_p_values
}
}
return(results_list)
}
calculate_power_fdr <- function(results, ground_truth_results, significance_level = 0.05) {
metrics_results <- list()
for (beta_s in names(results)) {
metrics_results[[beta_s]] <- list()
for (trans_name in names(results[[beta_s]])) {
p_values <- results[[beta_s]][[trans_name]]
true_effects <- ground_truth_results[[beta_s]]
significant_count = sum(true_effects)
TP <- sum(p_values < significance_level & true_effects)
FP <- sum(p_values < significance_level & !true_effects)
FN <- sum(p_values >= significance_level & true_effects)
power <- TP / significant_count
if (is.na(TP) || is.na(FP) || (TP + FP) == 0) {
FDR <- NA
} else {
FDR <- FP / (TP + FP)
}
metrics_results[[beta_s]][[trans_name]] <- list(Power = power, FDR = FDR)
}
}
return(metrics_results)
}
library(tibble)
main <- function() {
simulated_data <- gunifrac_list
transformation_functions <- list(
"ALR" = alr_transformation,
"CLR" = clr_transformation,
"Additive Logit Ratio" =logit_alr_transformation,
"Additive Arcsine Ratio" = arcsine_alr_transformation,
"Centered Logit Ratio" = logit_clr_transformation,
"Centered Arcsine Ratio" = arcsine_clr_transformation,
"Additive (New)Power Ratio" =dual_group_boxcox_alr_transformation,
"Centered (New)Power Ratio" = dual_group_boxcox_clr_transformation,
"Boxcox in Ratio - William" = boxcox_alr_transformation_william,
"New Boxcox in Ratio" = boxcox_alr_transformation_dual_group,
"Additive New Logit Ratio" = new_logit_alr_transformation,
"Centered New Logit Ratio" = new_logit_clr_transformation,
"ILR" = ilr_transformation,
"Additive Power Ratio" = power_alr_transformation,
"Centered Power Ratio" = power_clr_transformation,
"Additive Nothing Ratio" = nothing_alr_transformation,
"Centered Nothing Ratio" = nothing_clr_transformation,
)
results <- test_transformations(simulated_data, transformation_functions)
ground_truth_results <- results_list #calculate_ground_truth(simulated_data)
metrics_results <- calculate_power_fdr(results, ground_truth_results)
summary_table <- tibble(beta_s = character(), transformation = character(), power_fdr = character())
for (beta_s in names(metrics_results)) {
for (trans_name in names(metrics_results[[beta_s]])) {
power <- metrics_results[[beta_s]][[trans_name]]$Power
fdr <- metrics_results[[beta_s]][[trans_name]]$FDR
summary_table <- rbind(summary_table, tibble(beta_s = beta_s, transformation = trans_name, power = power, fdr = fdr))
}
}
return(summary_table)
}
library(dplyr)
n_simulation = 100
gunifrac_list = list()
results_list = list()
for (i in 1:n_simulation){
Simulated_data <- SimulateMSeqU(
para = para1, nSam = 100, nOTU = 100, diff.otu.pct = 0.1,
diff.otu.direct = "unbalanced",
diff.otu.mode = "mix",
user_specified_otu = NULL,
covariate.type = "binary",
grp.ratio = 1, covariate.eff.mean = 1, covariate.eff.sd = 0,
confounder.type = "both",
conf.cov.cor = 0.6, conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0.1,
confounder.eff.mean = 0, confounder.eff.sd = 0, error.sd = 0,
depth.mu = 1000, depth.theta = 5, depth.conf.factor = 0, cont.conf = 0, epsilon = 0
)
# Extract the OTU table and metadata
otu_df <- as.data.frame(Simulated_data$otu.tab.sim)
diff_otu_ids <- Simulated_data$otu.names[Simulated_data$diff.otu.ind]
meta.dat <- data.frame(
X = Simulated_data$covariate,
Z1 = Simulated_data$confounder[, 1],
Z2 = Simulated_data$confounder[, 2]
)
meta.dat$sample <- rownames(meta.dat)
# Transpose the OTU table
t_otu_df <- as.data.frame(t(otu_df))
# Keep the count data and merge with metadata
t_otu_df$sample <- rownames(t_otu_df)
merged_data_current <- merge(t_otu_df, meta.dat, by = "sample")
merged_data_current$group <- ifelse(merged_data_current$X == 0, "A", "B")
# Process the OTU table to include the group column and remove unnecessary columns
otu_df_processed <- merged_data_current %>%
select(group, everything()) %>%
select(-c(X, Z1, Z2, sample))
# Rename columns
col_names <- colnames(otu_df_processed)[-1]
indices <- match(diff_otu_ids, col_names)
indications <- ifelse(1:100 %in% indices, TRUE, FALSE)
results_list[[paste0("data_", i)]] <- indications
col_number <- as.integer(ncol(otu_df_processed))
colnames(otu_df_processed) <- c("group", paste0("X", seq(1, col_number - 1, by = 1)))
gunifrac_list[[paste0("data_",i)]] = otu_df_processed
}
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
n_simulation = 100
gunifrac_list = list()
results_list = list()
for (i in 1:n_simulation){
Simulated_data <- SimulateMSeqU(
para = para1, nSam = 100, nOTU = 100, diff.otu.pct = 0.1,
diff.otu.direct = "unbalanced",
diff.otu.mode = "mix",
user_specified_otu = NULL,
covariate.type = "binary",
grp.ratio = 1, covariate.eff.mean = 1, covariate.eff.sd = 0,
confounder.type = "both",
conf.cov.cor = 0.6, conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0.1,
confounder.eff.mean = 0, confounder.eff.sd = 0, error.sd = 0,
depth.mu = 1000, depth.theta = 5, depth.conf.factor = 0, cont.conf = 0, epsilon = 0
)
# Extract the OTU table and metadata
otu_df <- as.data.frame(Simulated_data$otu.tab.sim)
diff_otu_ids <- Simulated_data$otu.names[Simulated_data$diff.otu.ind]
meta.dat <- data.frame(
X = Simulated_data$covariate,
Z1 = Simulated_data$confounder[, 1],
Z2 = Simulated_data$confounder[, 2]
)
meta.dat$sample <- rownames(meta.dat)
# Transpose the OTU table
t_otu_df <- as.data.frame(t(otu_df))
# Keep the count data and merge with metadata
t_otu_df$sample <- rownames(t_otu_df)
merged_data_current <- merge(t_otu_df, meta.dat, by = "sample")
merged_data_current$group <- ifelse(merged_data_current$X == 0, "A", "B")
# Process the OTU table to include the group column and remove unnecessary columns
otu_df_processed <- merged_data_current %>%
select(group, everything()) %>%
select(-c(X, Z1, Z2, sample))
# Rename columns
col_names <- colnames(otu_df_processed)[-1]
indices <- match(diff_otu_ids, col_names)
indications <- ifelse(1:100 %in% indices, TRUE, FALSE)
results_list[[paste0("data_", i)]] <- indications
col_number <- as.integer(ncol(otu_df_processed))
colnames(otu_df_processed) <- c("group", paste0("X", seq(1, col_number - 1, by = 1)))
gunifrac_list[[paste0("data_",i)]] = otu_df_processed
}
library(dplyr)
library(MASS)
n_simulation = 100
gunifrac_list = list()
results_list = list()
for (i in 1:n_simulation){
Simulated_data <- SimulateMSeqU(
para = para1, nSam = 100, nOTU = 100, diff.otu.pct = 0.1,
diff.otu.direct = "unbalanced",
diff.otu.mode = "mix",
user_specified_otu = NULL,
covariate.type = "binary",
grp.ratio = 1, covariate.eff.mean = 1, covariate.eff.sd = 0,
confounder.type = "both",
conf.cov.cor = 0.6, conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0.1,
confounder.eff.mean = 0, confounder.eff.sd = 0, error.sd = 0,
depth.mu = 1000, depth.theta = 5, depth.conf.factor = 0, cont.conf = 0, epsilon = 0
)
# Extract the OTU table and metadata
otu_df <- as.data.frame(Simulated_data$otu.tab.sim)
diff_otu_ids <- Simulated_data$otu.names[Simulated_data$diff.otu.ind]
meta.dat <- data.frame(
X = Simulated_data$covariate,
Z1 = Simulated_data$confounder[, 1],
Z2 = Simulated_data$confounder[, 2]
)
meta.dat$sample <- rownames(meta.dat)
# Transpose the OTU table
t_otu_df <- as.data.frame(t(otu_df))
# Keep the count data and merge with metadata
t_otu_df$sample <- rownames(t_otu_df)
merged_data_current <- merge(t_otu_df, meta.dat, by = "sample")
merged_data_current$group <- ifelse(merged_data_current$X == 0, "A", "B")
# Process the OTU table to include the group column and remove unnecessary columns
otu_df_processed <- merged_data_current %>%
select(group, everything()) %>%
select(-c(X, Z1, Z2, sample))
# Rename columns
col_names <- colnames(otu_df_processed)[-1]
indices <- match(diff_otu_ids, col_names)
indications <- ifelse(1:100 %in% indices, TRUE, FALSE)
results_list[[paste0("data_", i)]] <- indications
col_number <- as.integer(ncol(otu_df_processed))
colnames(otu_df_processed) <- c("group", paste0("X", seq(1, col_number - 1, by = 1)))
gunifrac_list[[paste0("data_",i)]] = otu_df_processed
}
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
library(MASS)
n_simulation = 100
gunifrac_list = list()
results_list = list()
for (i in 1:n_simulation){
Simulated_data <- SimulateMSeqU(
para = para1, nSam = 100, nOTU = 100, diff.otu.pct = 0.1,
diff.otu.direct = "unbalanced",
diff.otu.mode = "mix",
user_specified_otu = NULL,
covariate.type = "binary",
grp.ratio = 1, covariate.eff.mean = 1, covariate.eff.sd = 0,
confounder.type = "both",
conf.cov.cor = 0.6, conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0.1,
confounder.eff.mean = 0, confounder.eff.sd = 0, error.sd = 0,
depth.mu = 1000, depth.theta = 5, depth.conf.factor = 0, cont.conf = 0, epsilon = 0
)
# Extract the OTU table and metadata
otu_df <- as.data.frame(Simulated_data$otu.tab.sim)
diff_otu_ids <- Simulated_data$otu.names[Simulated_data$diff.otu.ind]
meta.dat <- data.frame(
X = Simulated_data$covariate,
Z1 = Simulated_data$confounder[, 1],
Z2 = Simulated_data$confounder[, 2]
)
meta.dat$sample <- rownames(meta.dat)
# Transpose the OTU table
t_otu_df <- as.data.frame(t(otu_df))
# Keep the count data and merge with metadata
t_otu_df$sample <- rownames(t_otu_df)
merged_data_current <- merge(t_otu_df, meta.dat, by = "sample")
merged_data_current$group <- ifelse(merged_data_current$X == 0, "A", "B")
# Process the OTU table to include the group column and remove unnecessary columns
otu_df_processed <- merged_data_current %>%
select(group, everything()) %>%
select(-c(X, Z1, Z2, sample))
# Rename columns
col_names <- colnames(otu_df_processed)[-1]
indices <- match(diff_otu_ids, col_names)
indications <- ifelse(1:100 %in% indices, TRUE, FALSE)
results_list[[paste0("data_", i)]] <- indications
col_number <- as.integer(ncol(otu_df_processed))
colnames(otu_df_processed) <- c("group", paste0("X", seq(1, col_number - 1, by = 1)))
gunifrac_list[[paste0("data_",i)]] = otu_df_processed
}
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
library(MASS)
n_simulation = 100
gunifrac_list = list()
results_list = list()
for (i in 1:n_simulation){
Simulated_data <- SimulateMSeqU(
para = para1, nSam = 100, nOTU = 100, diff.otu.pct = 0.1,
diff.otu.direct = "unbalanced",
diff.otu.mode = "mix",
user_specified_otu = NULL,
covariate.type = "binary",
grp.ratio = 1, covariate.eff.mean = 1, covariate.eff.sd = 0,
confounder.type = "both",
conf.cov.cor = 0.6, conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0.1,
confounder.eff.mean = 0, confounder.eff.sd = 0, error.sd = 0,
depth.mu = 1000, depth.theta = 5, depth.conf.factor = 0, cont.conf = 0, epsilon = 0
)
# Extract the OTU table and metadata
otu_df <- as.data.frame(Simulated_data$otu.tab.sim)
diff_otu_ids <- Simulated_data$otu.names[Simulated_data$diff.otu.ind]
meta.dat <- data.frame(
X = Simulated_data$covariate,
Z1 = Simulated_data$confounder[, 1],
Z2 = Simulated_data$confounder[, 2]
)
meta.dat$sample <- rownames(meta.dat)
# Transpose the OTU table
t_otu_df <- as.data.frame(t(otu_df))
# Keep the count data and merge with metadata
t_otu_df$sample <- rownames(t_otu_df)
merged_data_current <- merge(t_otu_df, meta.dat, by = "sample")
merged_data_current$group <- ifelse(merged_data_current$X == 0, "A", "B")
# Process the OTU table to include the group column and remove unnecessary columns
otu_df_processed <- merged_data_current %>%
select(group, everything()) %>%
select(-c(X, Z1, Z2, sample))
# Rename columns
col_names <- colnames(otu_df_processed)[-1]
indices <- match(diff_otu_ids, col_names)
indications <- ifelse(1:100 %in% indices, TRUE, FALSE)
results_list[[paste0("data_", i)]] <- indications
col_number <- as.integer(ncol(otu_df_processed))
colnames(otu_df_processed) <- c("group", paste0("X", seq(1, col_number - 1, by = 1)))
gunifrac_list[[paste0("data_",i)]] = otu_df_processed
}
library(tidyverse)
models <- list()
summary_non_significant_as_reference = read.csv("summary_non_significant_as_reference.csv")
transformations <- unique(summary_non_significant_as_reference$transformation)
models <- list()
for (trans in transformations) {
subset_data <- summary_non_significant_as_reference %>%
filter(transformation == trans)
model <- lm(mean_fdr ~ alpha + beta0 + beta + q, data = subset_data)
models[[trans]] <- model
}
output_file <- "model_summaries_non_significant_as_reference_fdr.txt"
sink(output_file)
for (transformation in names(models)) {
cat("\nTransformation:", transformation, "\n")
print(summary(models[[transformation]]))
}
sink()
cat("Model summaries have been saved to", output_file, "\n")
model_summaries <- data.frame(Transformation = character(),
Intercept = numeric(),
alpha = numeric(),
beta0 = numeric(),
beta = numeric(),
q = numeric(),
stringsAsFactors = FALSE)
# Loop through each transformation and fit the linear regression model
for (trans in transformations) {
subset_data <- summary_non_significant_as_reference %>%
filter(transformation == trans)
model <- lm(mean_fdr ~ alpha + beta0 + beta + q, data = subset_data)
summary_model <- summary(model)
# Extract coefficients
intercept <- round(summary_model$coefficients[1, "Estimate"], 10)
alpha <- round(summary_model$coefficients[2, "Estimate"], 10)
beta0 <- round(summary_model$coefficients[3, "Estimate"], 10)
beta <- round(summary_model$coefficients[4, "Estimate"], 10)
q <- round(summary_model$coefficients[5, "Estimate"], 10)
# Add the model summary to the data frame
model_summaries <- rbind(model_summaries, data.frame(Transformation = trans,
Intercept = intercept,
alpha = alpha,
beta0 = beta0,
beta = beta,
q = q))
}
write.csv(model_summaries, "model_coefficient.csv", row.names = FALSE)
cat("Model summaries have been saved to model_coefficient_fdr.csv\n")
library(tidyverse)
models <- list()
summary_non_significant_as_reference = read.csv("summary_non_significant_as_reference.csv")
transformations <- unique(summary_non_significant_as_reference$transformation)
models <- list()
for (trans in transformations) {
subset_data <- summary_non_significant_as_reference %>%
filter(transformation == trans)
model <- lm(mean_power ~ alpha + beta0 + beta + q, data = subset_data)
models[[trans]] <- model
}
output_file <- "model_summaries_non_significant_as_reference.txt"
sink(output_file)
for (transformation in names(models)) {
cat("\nTransformation:", transformation, "\n")
print(summary(models[[transformation]]))
}
sink()
cat("Model summaries have been saved to", output_file, "\n")
model_summaries <- data.frame(Transformation = character(),
Intercept = numeric(),
alpha = numeric(),
beta0 = numeric(),
beta = numeric(),
q = numeric(),
stringsAsFactors = FALSE)
# Loop through each transformation and fit the linear regression model
for (trans in transformations) {
subset_data <- summary_non_significant_as_reference %>%
filter(transformation == trans)
model <- lm(mean_power ~ alpha + beta0 + beta + q, data = subset_data)
summary_model <- summary(model)
# Extract coefficients
intercept <- round(summary_model$coefficients[1, "Estimate"], 10)
alpha <- round(summary_model$coefficients[2, "Estimate"], 10)
beta0 <- round(summary_model$coefficients[3, "Estimate"], 10)
beta <- round(summary_model$coefficients[4, "Estimate"], 10)
q <- round(summary_model$coefficients[5, "Estimate"], 10)
# Add the model summary to the data frame
model_summaries <- rbind(model_summaries, data.frame(Transformation = trans,
Intercept = intercept,
alpha = alpha,
beta0 = beta0,
beta = beta,
q = q))
}
write.csv(model_summaries, "model_coefficient.csv", row.names = FALSE)
cat("Model summaries have been saved to model_coefficient.csv\n")
library(tidyverse)
models <- list()
summary_non_significant_as_reference = read.csv("summary_non_significant_as_reference.csv")
transformations <- unique(summary_non_significant_as_reference$transformation)
models <- list()
for (trans in transformations) {
subset_data <- summary_non_significant_as_reference %>%
filter(transformation == trans)
model <- lm(mean_fdr ~ alpha + beta0 + beta + q, data = subset_data)
models[[trans]] <- model
}
output_file <- "model_summaries_non_significant_as_reference_fdr.txt"
sink(output_file)
for (transformation in names(models)) {
cat("\nTransformation:", transformation, "\n")
print(summary(models[[transformation]]))
}
sink()
cat("Model summaries have been saved to", output_file, "\n")
model_summaries <- data.frame(Transformation = character(),
Intercept = numeric(),
alpha = numeric(),
beta0 = numeric(),
beta = numeric(),
q = numeric(),
stringsAsFactors = FALSE)
# Loop through each transformation and fit the linear regression model
for (trans in transformations) {
subset_data <- summary_non_significant_as_reference %>%
filter(transformation == trans)
model <- lm(mean_fdr ~ alpha + beta0 + beta + q, data = subset_data)
summary_model <- summary(model)
# Extract coefficients
intercept <- round(summary_model$coefficients[1, "Estimate"], 10)
alpha <- round(summary_model$coefficients[2, "Estimate"], 10)
beta0 <- round(summary_model$coefficients[3, "Estimate"], 10)
beta <- round(summary_model$coefficients[4, "Estimate"], 10)
q <- round(summary_model$coefficients[5, "Estimate"], 10)
# Add the model summary to the data frame
model_summaries <- rbind(model_summaries, data.frame(Transformation = trans,
Intercept = intercept,
alpha = alpha,
beta0 = beta0,
beta = beta,
q = q))
}
write.csv(model_summaries, "model_coefficient_fdr.csv", row.names = FALSE)
cat("Model summaries have been saved to model_coefficient_fdr.csv\n")
rbinom(100, 1, 0.2)
rnbinom(100, 1, 0.2)
rbinom(100, 1, 0.2)
rbinom(100, 1, 0.2)
rbinom(100, 1, 0.2)
rbinom(100, 1, 0.2)
1- rbinom(100, 1, 0.2)
